{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Import Necessary Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AutoTokenizer, AutoModel\nfrom torchvision import models, transforms\nfrom sklearn.metrics import classification_report\nfrom PIL import Image\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:07:45.279217Z","iopub.execute_input":"2025-01-27T17:07:45.279864Z","iopub.status.idle":"2025-01-27T17:07:57.269884Z","shell.execute_reply.started":"2025-01-27T17:07:45.279803Z","shell.execute_reply":"2025-01-27T17:07:57.268334Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# 2. Dataset Preparation","metadata":{}},{"cell_type":"code","source":"class MemeDataset(Dataset):\n    def __init__(self, df, image_folder, tokenizer, max_len, transform=None):\n        self.df = df\n        self.image_folder = image_folder\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image_path = f\"{self.image_folder}/{row['image_id']}.jpg\"\n        text = row['transcriptions']\n        label = row.get('labels', -1)  # -1 for test set\n\n        # Text Preprocessing\n        text_inputs = self.tokenizer(\n            text,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        # Image Preprocessing\n        image = Image.open(image_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        \n        return {\n            'image': image,\n            'text_inputs': {k: v.squeeze(0) for k, v in text_inputs.items()},\n            'label': torch.tensor(label, dtype=torch.long) if label != -1 else label\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:07:57.271527Z","iopub.execute_input":"2025-01-27T17:07:57.272175Z","iopub.status.idle":"2025-01-27T17:07:57.282061Z","shell.execute_reply.started":"2025-01-27T17:07:57.272139Z","shell.execute_reply":"2025-01-27T17:07:57.280383Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# 3. Model Definition","metadata":{}},{"cell_type":"code","source":"class MultimodalModel(nn.Module):\n    def __init__(self, muril_model_name, num_labels):\n        super(MultimodalModel, self).__init__()\n        \n        # MuRIL for Malayalam text\n        self.muril_model = AutoModel.from_pretrained(muril_model_name)\n        self.muril_fc = nn.Linear(self.muril_model.config.hidden_size, 256)\n        \n        # Image branch\n        self.image_model = models.resnet50(pretrained=True)\n        self.image_model.fc = nn.Linear(self.image_model.fc.in_features, 256)\n        \n        # Combined classifier\n        self.classifier = nn.Sequential(\n            nn.Linear(256 + 256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, num_labels)\n        )\n\n    def forward(self, text_inputs, image):\n        # Text features from MuRIL\n        muril_outputs = self.muril_model(**text_inputs)\n        muril_features = self.muril_fc(muril_outputs.pooler_output)\n\n        # Image features\n        image_features = self.image_model(image)\n\n        # Combine features\n        combined_features = torch.cat((muril_features, image_features), dim=1)\n        logits = self.classifier(combined_features)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:08:16.290512Z","iopub.execute_input":"2025-01-27T17:08:16.290929Z","iopub.status.idle":"2025-01-27T17:08:16.299806Z","shell.execute_reply.started":"2025-01-27T17:08:16.290900Z","shell.execute_reply":"2025-01-27T17:08:16.298214Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# 4. Training Function Definition","metadata":{}},{"cell_type":"code","source":"def train_model(model, dataloader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    all_preds = []\n    all_labels = []\n    for batch in dataloader:\n        images = batch['image'].to(device)\n        text_inputs = {k: v.to(device) for k, v in batch['text_inputs'].items()}\n        labels = batch['label'].to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(text_inputs, images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        \n        # Collect predictions and labels for classification report\n        # ------------ Code Goes Here -----------\n\n        # ------------ Code Goes Here -----------\n    \n    # Classification report\n    print(\"Train Classification Report:\")\n    print(classification_report(all_labels, all_preds))\n    \n    return total_loss / len(dataloader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Validation Function Definition","metadata":{}},{"cell_type":"code","source":"def validate_model(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for batch in dataloader:\n            images = batch['image'].to(device)\n            text_inputs = {k: v.to(device) for k, v in batch['text_inputs'].items()}\n            labels = batch['label'].to(device)\n            \n            outputs = model(text_inputs, images)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n            \n            # Collect predictions and labels for classification report\n            # ------------ Code Goes Here -----------\n\n            # ------------ Code Goes Here -----------\n    \n    # Classification report\n    print(\"Validation Classification Report:\")\n    print(classification_report(all_labels, all_preds))\n    \n    return total_loss / len(dataloader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Prediction Function Definition","metadata":{}},{"cell_type":"code","source":"def predict(model, dataloader, device):\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for batch in dataloader:\n            images = batch['image'].to(device)\n            text_inputs = {k: v.to(device) for k, v in batch['text_inputs'].items()}\n            outputs = model(text_inputs, images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n            predictions.extend(preds)\n    return predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Main Function Definition","metadata":{}},{"cell_type":"code","source":"def main():\n    # File paths and image folders\n    \n    # ------------ Code Goes Here -----------\n\n    # ------------ Code Goes Here -----------\n    \n    muril_model_name = \"google/muril-base-cased\"\n    max_len = 128\n    batch_size = 16\n    num_epochs = 45\n    lr = 2e-5\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Data Loader\n    tokenizer = AutoTokenizer.from_pretrained(muril_model_name)\n    transform = transforms.Compose([\n        # transforms.Resize((224, 224)),\n        # transforms.ToTensor(),\n        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n    train_df = pd.read_csv(train_csv)\n    dev_df = pd.read_csv(dev_csv)\n    test_df = pd.read_csv(test_csv)\n    \n    train_dataset = MemeDataset(train_df, train_image_folder, tokenizer, max_len, transform)\n    dev_dataset = MemeDataset(dev_df, dev_image_folder, tokenizer, max_len, transform)\n    test_dataset = MemeDataset(test_df, test_image_folder, tokenizer, max_len, transform)\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    dev_loader = DataLoader(dev_dataset, batch_size=batch_size)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n    \n    # Model Initialization\n    model = MultimodalModel(muril_model_name, num_labels=2).to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n    criterion = nn.CrossEntropyLoss()\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n    \n    # Train and validate model\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        train_loss = train_model(model, train_loader, optimizer, criterion, device)\n        val_loss = validate_model(model, dev_loader, criterion, device)\n        scheduler.step(val_loss)\n        print(f\"Train Loss = {train_loss:.4f}, Validation Loss = {val_loss:.4f}\")\n    \n    # Predict on test set\n    predictions = predict(model, test_loader, device)\n    test_df['labels'] = predictions\n\n    # Prediction saving in the file\n    # ------------ Code Goes Here -----------\n\n    # ------------ Code Goes Here -----------","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}