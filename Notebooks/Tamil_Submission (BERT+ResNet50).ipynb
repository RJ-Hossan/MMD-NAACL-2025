{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required libraries for data processing, model building, and image/text handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-27T16:56:44.653238Z",
     "iopub.status.busy": "2025-01-27T16:56:44.652837Z",
     "iopub.status.idle": "2025-01-27T16:56:44.658022Z",
     "shell.execute_reply": "2025-01-27T16:56:44.657057Z",
     "shell.execute_reply.started": "2025-01-27T16:56:44.653211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset Class Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a custom dataset class to handle text, images, and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T16:56:44.668554Z",
     "iopub.status.busy": "2025-01-27T16:56:44.668107Z",
     "iopub.status.idle": "2025-01-27T16:56:44.677861Z",
     "shell.execute_reply": "2025-01-27T16:56:44.676884Z",
     "shell.execute_reply.started": "2025-01-27T16:56:44.668518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MemeDataset(Dataset):\n",
    "    def __init__(self, df, image_folder, tokenizer, max_len, transform=None):\n",
    "        self.df = df\n",
    "        self.image_folder = image_folder\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = f\"{self.image_folder}/{row['image_id']}.jpg\"\n",
    "        text = row['transcriptions']\n",
    "        label = row.get('labels', -1)\n",
    "\n",
    "        # Text tokenization\n",
    "        text_inputs = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Image preprocessing\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Preprocessed image returning\n",
    "        return {\n",
    "            'image': image,\n",
    "            'text_inputs': {k: v.squeeze(0) for k, v in text_inputs.items()},\n",
    "            'label': torch.tensor(label, dtype=torch.long) if label != -1 else label\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T16:56:44.679742Z",
     "iopub.status.busy": "2025-01-27T16:56:44.679350Z",
     "iopub.status.idle": "2025-01-27T16:56:44.703213Z",
     "shell.execute_reply": "2025-01-27T16:56:44.701756Z",
     "shell.execute_reply.started": "2025-01-27T16:56:44.679705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultimodalModel(nn.Module):\n",
    "    def __init__(self, text_model_name, num_labels):\n",
    "        super(MultimodalModel, self).__init__()\n",
    "        # Text branch\n",
    "        self.text_model = AutoModel.from_pretrained(text_model_name)\n",
    "        self.text_fc = nn.Linear(self.text_model.config.hidden_size, 256)\n",
    "        \n",
    "        # Image branch\n",
    "        self.image_model = models.resnet50(pretrained=True)\n",
    "        self.image_model.fc = nn.Linear(self.image_model.fc.in_features, 256)\n",
    "        \n",
    "        # Combined classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 + 256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, text_inputs, image):\n",
    "        # Text features\n",
    "        text_outputs = self.text_model(**text_inputs)\n",
    "        text_features = self.text_fc(text_outputs.pooler_output)\n",
    "        \n",
    "        # Image features\n",
    "        image_features = self.image_model(image)\n",
    "        \n",
    "        # Combine features\n",
    "        # ------------- Code Goes Here -----------\n",
    "\n",
    "        # ------------- Code Goes Here -----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T16:56:44.705957Z",
     "iopub.status.busy": "2025-01-27T16:56:44.705506Z",
     "iopub.status.idle": "2025-01-27T16:56:44.725925Z",
     "shell.execute_reply": "2025-01-27T16:56:44.724713Z",
     "shell.execute_reply.started": "2025-01-27T16:56:44.705909Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        images = batch['image'].to(device)\n",
    "        text_inputs = {k: v.to(device) for k, v in batch['text_inputs'].items()}\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(text_inputs, images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Validation Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T16:56:44.727285Z",
     "iopub.status.busy": "2025-01-27T16:56:44.726947Z",
     "iopub.status.idle": "2025-01-27T16:56:44.745118Z",
     "shell.execute_reply": "2025-01-27T16:56:44.743814Z",
     "shell.execute_reply.started": "2025-01-27T16:56:44.727258Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def validate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch['image'].to(device)\n",
    "            text_inputs = {k: v.to(device) for k, v in batch['text_inputs'].items()}\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(text_inputs, images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Prediction Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T16:56:44.746742Z",
     "iopub.status.busy": "2025-01-27T16:56:44.746428Z",
     "iopub.status.idle": "2025-01-27T16:56:44.761393Z",
     "shell.execute_reply": "2025-01-27T16:56:44.760265Z",
     "shell.execute_reply.started": "2025-01-27T16:56:44.746713Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch['image'].to(device)\n",
    "            text_inputs = {k: v.to(device) for k, v in batch['text_inputs'].items()}\n",
    "            outputs = model(text_inputs, images)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Main Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T16:56:44.869721Z",
     "iopub.status.busy": "2025-01-27T16:56:44.869355Z",
     "iopub.status.idle": "2025-01-27T16:56:44.878710Z",
     "shell.execute_reply": "2025-01-27T16:56:44.877390Z",
     "shell.execute_reply.started": "2025-01-27T16:56:44.869692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define necessary train, dev, test file path with image folder paths\n",
    "    \n",
    "    # -------- There will be the required codes ---------\n",
    "\n",
    "    # -------- There will be the required codes ---------\n",
    "    \n",
    "    model_name = \"bert-base-uncased\"\n",
    "    max_len = 128\n",
    "    batch_size = 16\n",
    "    num_epochs = 45\n",
    "    lr = 2e-5\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Data loader\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    transform = transforms.Compose([\n",
    "        # transforms.Resize((224, 224)),\n",
    "        # transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_df = pd.read_csv(train_csv)\n",
    "    dev_df = pd.read_csv(dev_csv)\n",
    "    test_df = pd.read_csv(test_csv)\n",
    "    \n",
    "    train_dataset = MemeDataset(train_df, train_image_folder, tokenizer, max_len, transform)\n",
    "    dev_dataset = MemeDataset(dev_df, dev_image_folder, tokenizer, max_len, transform)\n",
    "    test_dataset = MemeDataset(test_df, test_image_folder, tokenizer, max_len, transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Model Initialization\n",
    "    # -------- There will be the required codes ---------\n",
    "    \n",
    "    # -------- There will be the required codes ---------\n",
    "    \n",
    "    # Train and validate model\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_model(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss = validate_model(model, dev_loader, criterion, device)\n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Validation Loss = {val_loss:.4f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    predictions = predict(model, test_loader, device)\n",
    "    test_df['labels'] = predictions\n",
    "\n",
    "    # Model prediction save in required file\n",
    "    # -------- There will be the required codes ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T16:57:03.402170Z",
     "iopub.status.busy": "2025-01-27T16:57:03.401764Z",
     "iopub.status.idle": "2025-01-27T16:57:03.406444Z",
     "shell.execute_reply": "2025-01-27T16:57:03.405198Z",
     "shell.execute_reply.started": "2025-01-27T16:57:03.402138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6437418,
     "sourceId": 10390929,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
